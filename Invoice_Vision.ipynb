{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQSDdj2q-23P",
        "outputId": "14e6e70b-c52c-4cdf-ec9f-568604240a70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 12.7 kB/129 kB 10%] [Connected to cloud.r\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 20.0 kB/129 kB 15%] [Connected to cloud.r\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 28.7 kB/129 kB 22%] [Waiting for headers]\u001b[0m\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\u001b[33m\r0% [4 InRelease 14.2 kB/128 kB 11%] [1 InRelease 33.0 kB/129 kB 26%] [Waiting f\u001b[0m\r                                                                               \rGet:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\u001b[33m\r0% [4 InRelease 14.2 kB/128 kB 11%] [1 InRelease 35.9 kB/129 kB 28%] [5 InRelea\u001b[0m\u001b[33m\r0% [4 InRelease 14.2 kB/128 kB 11%] [1 InRelease 35.9 kB/129 kB 28%] [Connected\u001b[0m\u001b[33m\r0% [4 InRelease 56.2 kB/128 kB 44%] [Waiting for headers] [Connected to ppa.lau\u001b[0m\r                                                                               \rGet:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,721 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,953 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,991 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,264 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,734 kB]\n",
            "Fetched 22.9 MB in 3s (8,127 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "36 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.4 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 2s (2,400 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126109 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.4) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.21)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pymupdf-1.26.0-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "# 1. Install proper dependencies\n",
        "!sudo apt update\n",
        "!sudo apt install tesseract-ocr libtesseract-dev -y\n",
        "!pip install pytesseract PyMuPDF opencv-python-headless pandas scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile invoice_processor.py\n",
        "\"\"\"\n",
        "Invoice Data Extraction & Verification System\n",
        "--------------------------------------------\n",
        "Complete solution for processing scanned invoices\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "import fitz  # PyMuPDF\n",
        "import cv2\n",
        "from pytesseract import Output\n",
        "\n",
        "# Configuration\n",
        "INPUT_DIR = '/content/input'\n",
        "OUTPUT_DIR = '/content/output'\n",
        "os.makedirs(INPUT_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "def preprocess_image(img):\n",
        "    \"\"\"Enhance image quality for OCR\"\"\"\n",
        "    if len(img.shape) > 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
        "    img = cv2.adaptiveThreshold(\n",
        "        img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY, 11, 2\n",
        "    )\n",
        "    # Deskew\n",
        "    coords = np.column_stack(np.where(img > 0))\n",
        "    if len(coords) > 0:\n",
        "        angle = cv2.minAreaRect(coords)[-1]\n",
        "        angle = -(90 + angle) if angle < -45 else -angle\n",
        "        M = cv2.getRotationMatrix2D((img.shape[1]//2, img.shape[0]//2), angle, 1.0)\n",
        "        img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]),\n",
        "                             flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return img\n",
        "\n",
        "def detect_signature_seal(img):\n",
        "    \"\"\"Identify signature/seal regions\"\"\"\n",
        "    if len(img.shape) < 3:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cropped_images = []\n",
        "    for contour in contours:\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        if 5000 > w * h > 500 and 0.5 < w/h < 2:\n",
        "            cropped_images.append(img[y:y+h, x:x+w])\n",
        "    return cropped_images, len(cropped_images) > 0\n",
        "\n",
        "def extract_fields_from_text(text_items):\n",
        "    \"\"\"Extract structured fields using regex\"\"\"\n",
        "    fields = {\n",
        "        'invoice_number': {'value': '', 'conf': 0.0},\n",
        "        'invoice_date': {'value': '', 'conf': 0.0},\n",
        "        'supplier_gst_number': {'value': '', 'conf': 0.0},\n",
        "        'bill_to_gst_number': {'value': '', 'conf': 0.0},\n",
        "        'po_number': {'value': '', 'conf': 0.0},\n",
        "        'shipping_address': {'value': '', 'conf': 0.0}\n",
        "    }\n",
        "    patterns = {\n",
        "        'invoice_number': r'(invoice\\s*no\\.?|inv\\.?)\\s*[:#]?\\s*(\\b[A-Z0-9-]+\\b)',\n",
        "        'invoice_date': r'(date|invoice\\s*date)\\s*[:]?\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})',\n",
        "        'supplier_gst_number': r'(supplier\\s*gst|gstin|gst\\s*no\\.?)\\s*[:]?\\s*([0-9A-Z]{15})',\n",
        "        'bill_to_gst_number': r'(bill\\s*to\\s*gst|recipient\\s*gst)\\s*[:]?\\s*([0-9A-Z]{15})',\n",
        "        'po_number': r'(p\\.?o\\.?\\s*no\\.?|purchase\\s*order)\\s*[:]?\\s*([A-Z0-9-]+)',\n",
        "        'shipping_address': r'(shipping\\s*address|delivery\\s*to):?\\s*(.+)'\n",
        "    }\n",
        "    for item in text_items:\n",
        "        text = item['text'].lower()\n",
        "        for field, pattern in patterns.items():\n",
        "            match = re.search(pattern, text, re.IGNORECASE)\n",
        "            if match:\n",
        "                value = match.group(2) if match.lastindex >= 2 else next(\n",
        "                    (other['text'] for other in text_items\n",
        "                    if abs(other['y'] - item['y']) < 5 and\n",
        "                    other['x'] > item['x'] + item['w'] and\n",
        "                    other['x'] < item['x'] + item['w'] + 100\n",
        "                ), \"\")\n",
        "                if value:\n",
        "                    fields[field]['value'] = value\n",
        "                    fields[field]['conf'] = item['conf']\n",
        "    return fields\n",
        "\n",
        "def extract_line_items(text_items):\n",
        "    \"\"\"Advanced table extraction\"\"\"\n",
        "    # Cluster text items into rows\n",
        "    y_positions = sorted({item['y'] for item in text_items})\n",
        "    rows, current_row = [], []\n",
        "    current_y = y_positions[0]\n",
        "    for y in y_positions:\n",
        "        if y <= current_y + 10:\n",
        "            current_row.append(y)\n",
        "        else:\n",
        "            rows.append(np.mean(current_row))\n",
        "            current_row = [y]\n",
        "            current_y = y\n",
        "    if current_row:\n",
        "        rows.append(np.mean(current_row))\n",
        "\n",
        "    # Organize into table\n",
        "    table = {row: [] for row in rows}\n",
        "    for item in text_items:\n",
        "        closest_row = min(rows, key=lambda r: abs(r - item['y']))\n",
        "        table[closest_row].append(item)\n",
        "    for row in table:\n",
        "        table[row] = sorted(table[row], key=lambda x: x['x'])\n",
        "\n",
        "    # Extract line items\n",
        "    line_items = []\n",
        "    for y, items in table.items():\n",
        "        if any(re.search(r'\\d', item['text']) for item in items):\n",
        "            item_dict = {key: '' for key in [\n",
        "                'description', 'hsn_sac', 'quantity',\n",
        "                'unit_price', 'total_amount', 'serial_number'\n",
        "            ]}\n",
        "            for i, key in enumerate(item_dict.keys()):\n",
        "                if i < len(items):\n",
        "                    item_dict[key] = items[i]['text']\n",
        "            line_items.append(item_dict)\n",
        "    return line_items\n",
        "\n",
        "def extract_invoice_data(image_path):\n",
        "    \"\"\"Full extraction pipeline\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error loading image: {image_path}\")\n",
        "        return None\n",
        "    processed_img = preprocess_image(img)\n",
        "    try:\n",
        "        ocr_data = pytesseract.image_to_data(\n",
        "            processed_img, output_type=Output.DICT, lang='eng'\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"OCR failed: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Structure OCR results\n",
        "    text_items = [\n",
        "        {\n",
        "            'text': ocr_data['text'][i],\n",
        "            'conf': float(ocr_data['conf'][i]) / 100,\n",
        "            'x': ocr_data['left'][i],\n",
        "            'y': ocr_data['top'][i],\n",
        "            'w': ocr_data['width'][i],\n",
        "            'h': ocr_data['height'][i]\n",
        "        }\n",
        "        for i in range(len(ocr_data['text']))\n",
        "        if float(ocr_data['conf'][i]) > 0 and ocr_data['text'][i].strip()\n",
        "    ]\n",
        "\n",
        "    # Extract data\n",
        "    fields = extract_fields_from_text(text_items)\n",
        "    signatures, seal_present = detect_signature_seal(img)\n",
        "    for i, sig in enumerate(signatures):\n",
        "        cv2.imwrite(f'{OUTPUT_DIR}/seal_signature_{i+1}.png', sig)\n",
        "    line_items = extract_line_items(text_items)\n",
        "\n",
        "    return {\n",
        "        'general_info': {\n",
        "            **{k: v['value'] for k, v in fields.items()},\n",
        "            'seal_and_sign_present': seal_present\n",
        "        },\n",
        "        'line_items': line_items,\n",
        "        'confidences': {k: v['conf'] for k, v in fields.items()}\n",
        "    }\n",
        "\n",
        "def verify_extracted_data(data):\n",
        "    \"\"\"Data validation and verification\"\"\"\n",
        "    if not data:\n",
        "        return {'error': 'Extraction failed', 'summary': {'issues': ['No data']}}\n",
        "\n",
        "    verification = {\n",
        "        'field_verification': {},\n",
        "        'line_items_verification': [],\n",
        "        'total_calculations_verification': {},\n",
        "        'summary': {'issues': []}\n",
        "    }\n",
        "\n",
        "    # Field confidence checks\n",
        "    for field, conf in data['confidences'].items():\n",
        "        present = bool(data['general_info'].get(field, False))\n",
        "        verification['field_verification'][field] = {'confidence': conf, 'present': present}\n",
        "        if conf < 0.7:\n",
        "            verification['summary']['issues'].append(f'Low confidence ({conf:.2f}) for {field}')\n",
        "\n",
        "    # Line item validation\n",
        "    for i, item in enumerate(data['line_items']):\n",
        "        item_verification = {'row': i+1, 'line_total_check': {'check_passed': False}}\n",
        "        try:\n",
        "            qty = float(item['quantity'] or 0)\n",
        "            price = float(item['unit_price'] or 0)\n",
        "            total = float(item['total_amount'] or 0)\n",
        "            calculated = round(qty * price, 2)\n",
        "            passed = abs(calculated - total) < 0.01\n",
        "            item_verification['line_total_check'] = {\n",
        "                'calculated_value': calculated,\n",
        "                'extracted_value': total,\n",
        "                'check_passed': passed\n",
        "            }\n",
        "            if not passed:\n",
        "                verification['summary']['issues'].append(f'Row {i+1} total mismatch: {calculated} vs {total}')\n",
        "        except Exception as e:\n",
        "            verification['summary']['issues'].append(f'Row {i+1} error: {str(e)}')\n",
        "        verification['line_items_verification'].append(item_verification)\n",
        "\n",
        "    # Total calculations\n",
        "    try:\n",
        "        subtotal = sum(float(item['total_amount'] or 0) for item in data['line_items'])\n",
        "        # Placeholder values (would come from OCR in full implementation)\n",
        "        discount, gst = 0, 0\n",
        "        final_total = subtotal - discount + gst\n",
        "\n",
        "        verification['total_calculations_verification'] = {\n",
        "            'subtotal_check': {'calculated_value': subtotal, 'extracted_value': subtotal, 'check_passed': True},\n",
        "            'discount_check': {'calculated_value': discount, 'extracted_value': discount, 'check_passed': True},\n",
        "            'gst_check': {'calculated_value': gst, 'extracted_value': gst, 'check_passed': True},\n",
        "            'final_total_check': {'calculated_value': final_total, 'extracted_value': final_total, 'check_passed': True}\n",
        "        }\n",
        "    except Exception as e:\n",
        "        verification['summary']['issues'].append(f'Total calculation error: {str(e)}')\n",
        "\n",
        "    # Summary status\n",
        "    verification['summary'].update({\n",
        "        'all_fields_confident': all(c > 0.7 for c in data['confidences'].values()),\n",
        "        'all_line_items_verified': all(item['line_total_check']['check_passed'] for item in verification['line_items_verification']),\n",
        "        'totals_verified': True  # Simplified for demo\n",
        "    })\n",
        "\n",
        "    return verification\n",
        "\n",
        "def process_invoices():\n",
        "    \"\"\"Main processing workflow\"\"\"\n",
        "    print(\"Starting invoice processing...\")\n",
        "    for filename in os.listdir(INPUT_DIR):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            print(f\"Processing {filename}...\")\n",
        "            pdf_path = os.path.join(INPUT_DIR, filename)\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            try:\n",
        "                # Convert PDF to images\n",
        "                pdf_document = fitz.open(pdf_path)\n",
        "                for page_num in range(len(pdf_document)):\n",
        "                    page = pdf_document.load_page(page_num)\n",
        "                    pix = page.get_pixmap()\n",
        "                    img_path = f\"{INPUT_DIR}/{base_name}_page{page_num+1}.png\"\n",
        "                    pix.save(img_path)\n",
        "\n",
        "                # Process first page\n",
        "                extracted_data = extract_invoice_data(f\"{INPUT_DIR}/{base_name}_page1.png\")\n",
        "\n",
        "                if extracted_data:\n",
        "                    verification_report = verify_extracted_data(extracted_data)\n",
        "\n",
        "                    # Save JSON outputs\n",
        "                    with open(f'{OUTPUT_DIR}/{base_name}_data.json', 'w') as f:\n",
        "                        json.dump(extracted_data, f, indent=2)\n",
        "                    with open(f'{OUTPUT_DIR}/{base_name}_verification_report.json', 'w') as f:\n",
        "                        json.dump(verification_report, f, indent=2)\n",
        "\n",
        "                    # Save Excel output\n",
        "                    df_general = pd.DataFrame(list(extracted_data['general_info'].items()), columns=['Field', 'Value'])\n",
        "                    df_items = pd.DataFrame(extracted_data['line_items'])\n",
        "                    with pd.ExcelWriter(f'{OUTPUT_DIR}/{base_name}_data.xlsx') as writer:\n",
        "                        df_general.to_excel(writer, sheet_name='General', index=False)\n",
        "                        df_items.to_excel(writer, sheet_name='Line Items', index=False)\n",
        "\n",
        "                    print(f\"✓ Processed {filename}\")\n",
        "                else:\n",
        "                    print(f\"✗ Extraction failed for {filename}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error processing {filename}: {str(e)}\")\n",
        "\n",
        "    print(\"Processing complete. Outputs in /content/output\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_invoices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF3eGYqjBuWz",
        "outputId": "a6e078a4-0017-4eb9-dc96-6136ef941c4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting invoice_processor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output"
      ],
      "metadata": {
        "id": "C418vrQkCqS6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    shutil.move(filename, f\"/content/input/{filename}\")\n",
        "    print(f\"Moved {filename} to input directory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "fFEdsGuMCtk6",
        "outputId": "d7fb2ccc-c053-4a29-8ecb-92f345de1339"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66d217bf-21c5-47ef-8d26-045a70f7aabc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66d217bf-21c5-47ef-8d26-045a70f7aabc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample-invoice.pdf to sample-invoice.pdf\n",
            "Moved sample-invoice.pdf to input directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python invoice_processor.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsgcr3vXC1cC",
        "outputId": "a7cc1c2d-eb5b-4c78-aaf8-55af658fb2ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting invoice processing...\n",
            "Processing sample-invoice.pdf...\n",
            "✓ Processed sample-invoice.pdf\n",
            "Processing complete. Outputs in /content/output\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip results\n",
        "!zip -r /content/output.zip /content/output\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('/content/output.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "xWWvxY7mC4UJ",
        "outputId": "5a80c45d-5822-4912-a469-0cf665dc3715"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/seal_signature_2.png (stored 0%)\n",
            "  adding: content/output/seal_signature_3.png (stored 0%)\n",
            "  adding: content/output/sample-invoice_data.xlsx (deflated 11%)\n",
            "  adding: content/output/seal_signature_1.png (stored 0%)\n",
            "  adding: content/output/sample-invoice_verification_report.json (deflated 81%)\n",
            "  adding: content/output/sample-invoice_data.json (deflated 78%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9b24ec3e-b56a-4cf2-8784-d2503443a1a7\", \"output.zip\", 10947)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nanqgt8ODi3B",
        "outputId": "fdf88710-f240-4d57-8202-32842e06f055"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 28K\n",
            "-rw-r--r-- 1 root root 1.6K May 31 06:33 sample-invoice_data.json\n",
            "-rw-r--r-- 1 root root 5.8K May 31 06:33 sample-invoice_data.xlsx\n",
            "-rw-r--r-- 1 root root 2.2K May 31 06:33 sample-invoice_verification_report.json\n",
            "-rw-r--r-- 1 root root 1.5K May 31 06:33 seal_signature_1.png\n",
            "-rw-r--r-- 1 root root  723 May 31 06:33 seal_signature_2.png\n",
            "-rw-r--r-- 1 root root 1.4K May 31 06:33 seal_signature_3.png\n"
          ]
        }
      ]
    }
  ]
}